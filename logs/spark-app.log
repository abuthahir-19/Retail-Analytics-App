2025-07-09 21:27:11 [main] INFO  org.apache.spark.SparkContext - Running Spark version 3.5.3
2025-07-09 21:27:11 [main] INFO  org.apache.spark.SparkContext - OS info Windows 11, 10.0, amd64
2025-07-09 21:27:11 [main] INFO  org.apache.spark.SparkContext - Java version 11.0.26
2025-07-09 21:27:12 [main] INFO  org.apache.spark.resource.ResourceUtils - ==============================================================
2025-07-09 21:27:12 [main] INFO  org.apache.spark.resource.ResourceUtils - No custom resources configured for spark.driver.
2025-07-09 21:27:12 [main] INFO  org.apache.spark.resource.ResourceUtils - ==============================================================
2025-07-09 21:27:12 [main] INFO  org.apache.spark.SparkContext - Submitted application: Spark Testing Session Establishment
2025-07-09 21:27:12 [main] INFO  org.apache.spark.resource.ResourceProfile - Default ResourceProfile created, executor resources: Map(cores -> name: cores, amount: 1, script: , vendor: , memory -> name: memory, amount: 1024, script: , vendor: , offHeap -> name: offHeap, amount: 0, script: , vendor: ), task resources: Map(cpus -> name: cpus, amount: 1.0)
2025-07-09 21:27:12 [main] INFO  org.apache.spark.resource.ResourceProfile - Limiting resource is cpu
2025-07-09 21:27:12 [main] INFO  org.apache.spark.resource.ResourceProfileManager - Added ResourceProfile id: 0
2025-07-09 21:27:13 [main] INFO  org.apache.spark.SecurityManager - Changing view acls to: abuth
2025-07-09 21:27:13 [main] INFO  org.apache.spark.SecurityManager - Changing modify acls to: abuth
2025-07-09 21:27:13 [main] INFO  org.apache.spark.SecurityManager - Changing view acls groups to: 
2025-07-09 21:27:13 [main] INFO  org.apache.spark.SecurityManager - Changing modify acls groups to: 
2025-07-09 21:27:13 [main] INFO  org.apache.spark.SecurityManager - SecurityManager: authentication disabled; ui acls disabled; users with view permissions: abuth; groups with view permissions: EMPTY; users with modify permissions: abuth; groups with modify permissions: EMPTY
2025-07-09 21:27:14 [main] INFO  org.apache.spark.util.Utils - Successfully started service 'sparkDriver' on port 55299.
2025-07-09 21:27:14 [main] INFO  org.apache.spark.SparkEnv - Registering MapOutputTracker
2025-07-09 21:27:14 [main] INFO  org.apache.spark.SparkEnv - Registering BlockManagerMaster
2025-07-09 21:27:14 [main] INFO  org.apache.spark.storage.BlockManagerMasterEndpoint - Using org.apache.spark.storage.DefaultTopologyMapper for getting topology information
2025-07-09 21:27:14 [main] INFO  org.apache.spark.storage.BlockManagerMasterEndpoint - BlockManagerMasterEndpoint up
2025-07-09 21:27:14 [main] INFO  org.apache.spark.SparkEnv - Registering BlockManagerMasterHeartbeat
2025-07-09 21:27:14 [main] INFO  org.apache.spark.storage.DiskBlockManager - Created local directory at C:\Users\abuth\AppData\Local\Temp\blockmgr-da9d97b1-a45b-45f0-9e1d-a234978d2c75
2025-07-09 21:27:14 [main] INFO  org.apache.spark.storage.memory.MemoryStore - MemoryStore started with capacity 2.2 GiB
2025-07-09 21:27:14 [main] INFO  org.apache.spark.SparkEnv - Registering OutputCommitCoordinator
2025-07-09 21:27:14 [main] INFO  org.sparkproject.jetty.util.log - Logging initialized @6411ms to org.sparkproject.jetty.util.log.Slf4jLog
2025-07-09 21:27:15 [main] INFO  org.apache.spark.ui.JettyUtils - Start Jetty 0.0.0.0:4040 for SparkUI
2025-07-09 21:27:15 [main] INFO  org.sparkproject.jetty.server.Server - jetty-9.4.54.v20240208; built: 2024-02-08T19:42:39.027Z; git: cef3fbd6d736a21e7d541a5db490381d95a2047d; jvm 11.0.26+7-LTS-187
2025-07-09 21:27:15 [main] INFO  org.sparkproject.jetty.server.Server - Started @6648ms
2025-07-09 21:27:15 [main] INFO  org.sparkproject.jetty.server.AbstractConnector - Started ServerConnector@4ac8768e{HTTP/1.1, (http/1.1)}{0.0.0.0:4040}
2025-07-09 21:27:15 [main] INFO  org.apache.spark.util.Utils - Successfully started service 'SparkUI' on port 4040.
2025-07-09 21:27:15 [main] INFO  org.sparkproject.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@5ff00507{/,null,AVAILABLE,@Spark}
2025-07-09 21:27:15 [main] INFO  org.apache.spark.executor.Executor - Starting executor ID driver on host DESKTOP-1DMF534.bbrouter
2025-07-09 21:27:15 [main] INFO  org.apache.spark.executor.Executor - OS info Windows 11, 10.0, amd64
2025-07-09 21:27:15 [main] INFO  org.apache.spark.executor.Executor - Java version 11.0.26
2025-07-09 21:27:15 [main] INFO  org.apache.spark.executor.Executor - Starting executor with user classpath (userClassPathFirst = false): ''
2025-07-09 21:27:15 [main] INFO  org.apache.spark.executor.Executor - Created or updated repl class loader org.apache.spark.util.MutableURLClassLoader@721d5b74 for default.
2025-07-09 21:27:15 [main] INFO  org.apache.spark.util.Utils - Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 55342.
2025-07-09 21:27:15 [main] INFO  org.apache.spark.network.netty.NettyBlockTransferService - Server created on DESKTOP-1DMF534.bbrouter:55342
2025-07-09 21:27:15 [main] INFO  org.apache.spark.storage.BlockManager - Using org.apache.spark.storage.RandomBlockReplicationPolicy for block replication policy
2025-07-09 21:27:15 [main] INFO  org.apache.spark.storage.BlockManagerMaster - Registering BlockManager BlockManagerId(driver, DESKTOP-1DMF534.bbrouter, 55342, None)
2025-07-09 21:27:15 [dispatcher-BlockManagerMaster] INFO  org.apache.spark.storage.BlockManagerMasterEndpoint - Registering block manager DESKTOP-1DMF534.bbrouter:55342 with 2.2 GiB RAM, BlockManagerId(driver, DESKTOP-1DMF534.bbrouter, 55342, None)
2025-07-09 21:27:15 [main] INFO  org.apache.spark.storage.BlockManagerMaster - Registered BlockManager BlockManagerId(driver, DESKTOP-1DMF534.bbrouter, 55342, None)
2025-07-09 21:27:15 [main] INFO  org.apache.spark.storage.BlockManager - Initialized BlockManager: BlockManagerId(driver, DESKTOP-1DMF534.bbrouter, 55342, None)
2025-07-09 21:27:15 [main] INFO  org.sparkproject.jetty.server.handler.ContextHandler - Stopped o.s.j.s.ServletContextHandler@5ff00507{/,null,STOPPED,@Spark}
2025-07-09 21:27:15 [main] INFO  org.sparkproject.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@19fec3d6{/jobs,null,AVAILABLE,@Spark}
2025-07-09 21:27:15 [main] INFO  org.sparkproject.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@b768a65{/jobs/json,null,AVAILABLE,@Spark}
2025-07-09 21:27:15 [main] INFO  org.sparkproject.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@39266403{/jobs/job,null,AVAILABLE,@Spark}
2025-07-09 21:27:15 [main] INFO  org.sparkproject.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@2aa14ae6{/jobs/job/json,null,AVAILABLE,@Spark}
2025-07-09 21:27:15 [main] INFO  org.sparkproject.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@4168f3d9{/stages,null,AVAILABLE,@Spark}
2025-07-09 21:27:15 [main] INFO  org.sparkproject.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@15e8f9b2{/stages/json,null,AVAILABLE,@Spark}
2025-07-09 21:27:15 [main] INFO  org.sparkproject.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@68631b1d{/stages/stage,null,AVAILABLE,@Spark}
2025-07-09 21:27:15 [main] INFO  org.sparkproject.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@a0c5be{/stages/stage/json,null,AVAILABLE,@Spark}
2025-07-09 21:27:15 [main] INFO  org.sparkproject.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@14efa279{/stages/pool,null,AVAILABLE,@Spark}
2025-07-09 21:27:15 [main] INFO  org.sparkproject.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@e62319f{/stages/pool/json,null,AVAILABLE,@Spark}
2025-07-09 21:27:15 [main] INFO  org.sparkproject.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@24a0c58b{/storage,null,AVAILABLE,@Spark}
2025-07-09 21:27:15 [main] INFO  org.sparkproject.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@7f3c0399{/storage/json,null,AVAILABLE,@Spark}
2025-07-09 21:27:15 [main] INFO  org.sparkproject.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@3a11c0eb{/storage/rdd,null,AVAILABLE,@Spark}
2025-07-09 21:27:15 [main] INFO  org.sparkproject.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@2c2c3947{/storage/rdd/json,null,AVAILABLE,@Spark}
2025-07-09 21:27:15 [main] INFO  org.sparkproject.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@7ec08115{/environment,null,AVAILABLE,@Spark}
2025-07-09 21:27:15 [main] INFO  org.sparkproject.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@1e76afeb{/environment/json,null,AVAILABLE,@Spark}
2025-07-09 21:27:15 [main] INFO  org.sparkproject.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@3e4d40ea{/executors,null,AVAILABLE,@Spark}
2025-07-09 21:27:15 [main] INFO  org.sparkproject.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@2c9d90fc{/executors/json,null,AVAILABLE,@Spark}
2025-07-09 21:27:15 [main] INFO  org.sparkproject.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@418f890f{/executors/threadDump,null,AVAILABLE,@Spark}
2025-07-09 21:27:15 [main] INFO  org.sparkproject.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@7d66e544{/executors/threadDump/json,null,AVAILABLE,@Spark}
2025-07-09 21:27:15 [main] INFO  org.sparkproject.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@5b1c32e4{/executors/heapHistogram,null,AVAILABLE,@Spark}
2025-07-09 21:27:15 [main] INFO  org.sparkproject.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@48bc2fce{/executors/heapHistogram/json,null,AVAILABLE,@Spark}
2025-07-09 21:27:15 [main] INFO  org.sparkproject.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@24fba488{/static,null,AVAILABLE,@Spark}
2025-07-09 21:27:15 [main] INFO  org.sparkproject.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@66f16742{/,null,AVAILABLE,@Spark}
2025-07-09 21:27:15 [main] INFO  org.sparkproject.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@3c54ddec{/api,null,AVAILABLE,@Spark}
2025-07-09 21:27:15 [main] INFO  org.sparkproject.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@35025a0a{/jobs/job/kill,null,AVAILABLE,@Spark}
2025-07-09 21:27:15 [main] INFO  org.sparkproject.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@7c70aae1{/stages/stage/kill,null,AVAILABLE,@Spark}
2025-07-09 21:27:15 [main] INFO  org.sparkproject.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@2a0b901c{/metrics/json,null,AVAILABLE,@Spark}
2025-07-09 21:27:16 [main] INFO  org.apache.spark.sql.internal.SharedState - Setting hive.metastore.warehouse.dir ('null') to the value of spark.sql.warehouse.dir.
2025-07-09 21:27:16 [main] INFO  org.apache.spark.sql.internal.SharedState - Warehouse path is 'file:/E:/JavaSpark/Retail_Analytics_Platform/spark-warehouse'.
2025-07-09 21:27:16 [main] INFO  org.sparkproject.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@25ad25f5{/SQL,null,AVAILABLE,@Spark}
2025-07-09 21:27:16 [main] INFO  org.sparkproject.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@1860a7a1{/SQL/json,null,AVAILABLE,@Spark}
2025-07-09 21:27:16 [main] INFO  org.sparkproject.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@3e03046d{/SQL/execution,null,AVAILABLE,@Spark}
2025-07-09 21:27:16 [main] INFO  org.sparkproject.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@74e497ae{/SQL/execution/json,null,AVAILABLE,@Spark}
2025-07-09 21:27:16 [main] INFO  org.sparkproject.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@45d4421d{/static/sql,null,AVAILABLE,@Spark}
2025-07-09 21:27:18 [main] INFO  com.learnJava.lib.TransformationTest - Sample test data
2025-07-09 21:27:19 [main] INFO  org.apache.spark.sql.catalyst.expressions.codegen.CodeGenerator - Code generated in 253.4525 ms
2025-07-09 21:27:20 [main] INFO  org.apache.spark.sql.catalyst.expressions.codegen.CodeGenerator - Code generated in 34.6247 ms
2025-07-09 21:27:21 [main] INFO  org.apache.spark.sql.catalyst.expressions.codegen.CodeGenerator - Code generated in 14.7536 ms
2025-07-09 21:27:21 [main] INFO  org.apache.spark.sql.catalyst.expressions.codegen.CodeGenerator - Code generated in 88.7471 ms
2025-07-09 21:27:21 [main] INFO  org.apache.spark.sql.catalyst.expressions.codegen.CodeGenerator - Code generated in 8.4374 ms
2025-07-09 21:27:21 [dag-scheduler-event-loop] INFO  org.apache.spark.scheduler.DAGScheduler - Registering RDD 2 (collectAsList at TransformationTest.java:72) as input to shuffle 0
2025-07-09 21:27:21 [dag-scheduler-event-loop] INFO  org.apache.spark.scheduler.DAGScheduler - Got map stage job 0 (collectAsList at TransformationTest.java:72) with 6 output partitions
2025-07-09 21:27:21 [dag-scheduler-event-loop] INFO  org.apache.spark.scheduler.DAGScheduler - Final stage: ShuffleMapStage 0 (collectAsList at TransformationTest.java:72)
2025-07-09 21:27:21 [dag-scheduler-event-loop] INFO  org.apache.spark.scheduler.DAGScheduler - Parents of final stage: List()
2025-07-09 21:27:21 [dag-scheduler-event-loop] INFO  org.apache.spark.scheduler.DAGScheduler - Missing parents: List()
2025-07-09 21:27:21 [dag-scheduler-event-loop] INFO  org.apache.spark.scheduler.DAGScheduler - Submitting ShuffleMapStage 0 (MapPartitionsRDD[2] at collectAsList at TransformationTest.java:72), which has no missing parents
2025-07-09 21:27:22 [dag-scheduler-event-loop] INFO  org.apache.spark.storage.memory.MemoryStore - Block broadcast_0 stored as values in memory (estimated size 21.6 KiB, free 2.2 GiB)
2025-07-09 21:27:22 [dag-scheduler-event-loop] INFO  org.apache.spark.storage.memory.MemoryStore - Block broadcast_0_piece0 stored as bytes in memory (estimated size 9.9 KiB, free 2.2 GiB)
2025-07-09 21:27:22 [dispatcher-BlockManagerMaster] INFO  org.apache.spark.storage.BlockManagerInfo - Added broadcast_0_piece0 in memory on DESKTOP-1DMF534.bbrouter:55342 (size: 9.9 KiB, free: 2.2 GiB)
2025-07-09 21:27:22 [dag-scheduler-event-loop] INFO  org.apache.spark.SparkContext - Created broadcast 0 from broadcast at DAGScheduler.scala:1585
2025-07-09 21:27:22 [dag-scheduler-event-loop] INFO  org.apache.spark.scheduler.DAGScheduler - Submitting 6 missing tasks from ShuffleMapStage 0 (MapPartitionsRDD[2] at collectAsList at TransformationTest.java:72) (first 15 tasks are for partitions Vector(0, 1, 2, 3, 4, 5))
2025-07-09 21:27:22 [dag-scheduler-event-loop] INFO  org.apache.spark.scheduler.TaskSchedulerImpl - Adding task set 0.0 with 6 tasks resource profile 0
2025-07-09 21:27:22 [dispatcher-event-loop-6] INFO  org.apache.spark.scheduler.TaskSetManager - Starting task 0.0 in stage 0.0 (TID 0) (DESKTOP-1DMF534.bbrouter, executor driver, partition 0, PROCESS_LOCAL, 9168 bytes) 
2025-07-09 21:27:22 [dispatcher-event-loop-6] INFO  org.apache.spark.scheduler.TaskSetManager - Starting task 1.0 in stage 0.0 (TID 1) (DESKTOP-1DMF534.bbrouter, executor driver, partition 1, PROCESS_LOCAL, 9168 bytes) 
2025-07-09 21:27:22 [dispatcher-event-loop-6] INFO  org.apache.spark.scheduler.TaskSetManager - Starting task 2.0 in stage 0.0 (TID 2) (DESKTOP-1DMF534.bbrouter, executor driver, partition 2, PROCESS_LOCAL, 9168 bytes) 
2025-07-09 21:27:22 [dispatcher-event-loop-6] INFO  org.apache.spark.scheduler.TaskSetManager - Starting task 3.0 in stage 0.0 (TID 3) (DESKTOP-1DMF534.bbrouter, executor driver, partition 3, PROCESS_LOCAL, 9176 bytes) 
2025-07-09 21:27:22 [dispatcher-event-loop-6] INFO  org.apache.spark.scheduler.TaskSetManager - Starting task 4.0 in stage 0.0 (TID 4) (DESKTOP-1DMF534.bbrouter, executor driver, partition 4, PROCESS_LOCAL, 9176 bytes) 
2025-07-09 21:27:22 [dispatcher-event-loop-6] INFO  org.apache.spark.scheduler.TaskSetManager - Starting task 5.0 in stage 0.0 (TID 5) (DESKTOP-1DMF534.bbrouter, executor driver, partition 5, PROCESS_LOCAL, 9168 bytes) 
2025-07-09 21:27:22 [Executor task launch worker for task 4.0 in stage 0.0 (TID 4)] INFO  org.apache.spark.executor.Executor - Running task 4.0 in stage 0.0 (TID 4)
2025-07-09 21:27:22 [Executor task launch worker for task 2.0 in stage 0.0 (TID 2)] INFO  org.apache.spark.executor.Executor - Running task 2.0 in stage 0.0 (TID 2)
2025-07-09 21:27:22 [Executor task launch worker for task 5.0 in stage 0.0 (TID 5)] INFO  org.apache.spark.executor.Executor - Running task 5.0 in stage 0.0 (TID 5)
2025-07-09 21:27:22 [Executor task launch worker for task 0.0 in stage 0.0 (TID 0)] INFO  org.apache.spark.executor.Executor - Running task 0.0 in stage 0.0 (TID 0)
2025-07-09 21:27:22 [Executor task launch worker for task 3.0 in stage 0.0 (TID 3)] INFO  org.apache.spark.executor.Executor - Running task 3.0 in stage 0.0 (TID 3)
2025-07-09 21:27:22 [Executor task launch worker for task 1.0 in stage 0.0 (TID 1)] INFO  org.apache.spark.executor.Executor - Running task 1.0 in stage 0.0 (TID 1)
2025-07-09 21:27:22 [Executor task launch worker for task 4.0 in stage 0.0 (TID 4)] INFO  org.apache.spark.sql.catalyst.expressions.codegen.CodeGenerator - Code generated in 33.323 ms
2025-07-09 21:27:22 [Executor task launch worker for task 1.0 in stage 0.0 (TID 1)] INFO  org.apache.spark.sql.catalyst.expressions.codegen.CodeGenerator - Code generated in 15.1765 ms
2025-07-09 21:27:22 [Executor task launch worker for task 4.0 in stage 0.0 (TID 4)] INFO  org.apache.spark.sql.catalyst.expressions.codegen.CodeGenerator - Code generated in 7.3137 ms
2025-07-09 21:27:22 [Executor task launch worker for task 1.0 in stage 0.0 (TID 1)] INFO  org.apache.spark.sql.catalyst.expressions.codegen.CodeGenerator - Code generated in 33.6652 ms
2025-07-09 21:27:22 [Executor task launch worker for task 4.0 in stage 0.0 (TID 4)] INFO  org.apache.spark.executor.Executor - Finished task 4.0 in stage 0.0 (TID 4). 2503 bytes result sent to driver
2025-07-09 21:27:22 [Executor task launch worker for task 5.0 in stage 0.0 (TID 5)] INFO  org.apache.spark.executor.Executor - Finished task 5.0 in stage 0.0 (TID 5). 2503 bytes result sent to driver
2025-07-09 21:27:22 [Executor task launch worker for task 0.0 in stage 0.0 (TID 0)] INFO  org.apache.spark.executor.Executor - Finished task 0.0 in stage 0.0 (TID 0). 2503 bytes result sent to driver
2025-07-09 21:27:22 [Executor task launch worker for task 1.0 in stage 0.0 (TID 1)] INFO  org.apache.spark.executor.Executor - Finished task 1.0 in stage 0.0 (TID 1). 2503 bytes result sent to driver
2025-07-09 21:27:22 [Executor task launch worker for task 3.0 in stage 0.0 (TID 3)] INFO  org.apache.spark.executor.Executor - Finished task 3.0 in stage 0.0 (TID 3). 2503 bytes result sent to driver
2025-07-09 21:27:22 [Executor task launch worker for task 2.0 in stage 0.0 (TID 2)] INFO  org.apache.spark.executor.Executor - Finished task 2.0 in stage 0.0 (TID 2). 2503 bytes result sent to driver
2025-07-09 21:27:22 [task-result-getter-1] INFO  org.apache.spark.scheduler.TaskSetManager - Finished task 1.0 in stage 0.0 (TID 1) in 523 ms on DESKTOP-1DMF534.bbrouter (executor driver) (1/6)
2025-07-09 21:27:22 [task-result-getter-3] INFO  org.apache.spark.scheduler.TaskSetManager - Finished task 4.0 in stage 0.0 (TID 4) in 532 ms on DESKTOP-1DMF534.bbrouter (executor driver) (2/6)
2025-07-09 21:27:22 [task-result-getter-2] INFO  org.apache.spark.scheduler.TaskSetManager - Finished task 5.0 in stage 0.0 (TID 5) in 531 ms on DESKTOP-1DMF534.bbrouter (executor driver) (3/6)
2025-07-09 21:27:22 [task-result-getter-0] INFO  org.apache.spark.scheduler.TaskSetManager - Finished task 0.0 in stage 0.0 (TID 0) in 561 ms on DESKTOP-1DMF534.bbrouter (executor driver) (4/6)
2025-07-09 21:27:22 [task-result-getter-3] INFO  org.apache.spark.scheduler.TaskSetManager - Finished task 2.0 in stage 0.0 (TID 2) in 538 ms on DESKTOP-1DMF534.bbrouter (executor driver) (5/6)
2025-07-09 21:27:22 [task-result-getter-1] INFO  org.apache.spark.scheduler.TaskSetManager - Finished task 3.0 in stage 0.0 (TID 3) in 536 ms on DESKTOP-1DMF534.bbrouter (executor driver) (6/6)
2025-07-09 21:27:22 [task-result-getter-1] INFO  org.apache.spark.scheduler.TaskSchedulerImpl - Removed TaskSet 0.0, whose tasks have all completed, from pool 
2025-07-09 21:27:22 [dag-scheduler-event-loop] INFO  org.apache.spark.scheduler.DAGScheduler - ShuffleMapStage 0 (collectAsList at TransformationTest.java:72) finished in 1.095 s
2025-07-09 21:27:22 [dag-scheduler-event-loop] INFO  org.apache.spark.scheduler.DAGScheduler - looking for newly runnable stages
2025-07-09 21:27:22 [dag-scheduler-event-loop] INFO  org.apache.spark.scheduler.DAGScheduler - running: Set()
2025-07-09 21:27:22 [dag-scheduler-event-loop] INFO  org.apache.spark.scheduler.DAGScheduler - waiting: Set()
2025-07-09 21:27:22 [dag-scheduler-event-loop] INFO  org.apache.spark.scheduler.DAGScheduler - failed: Set()
2025-07-09 21:27:23 [main] INFO  org.apache.spark.sql.execution.adaptive.ShufflePartitionsUtil - For shuffle(0), advisory target size: 67108864, actual target size 1048576, minimum partition size: 1048576
2025-07-09 21:27:23 [main] INFO  org.apache.spark.sql.catalyst.expressions.codegen.CodeGenerator - Code generated in 48.1965 ms
2025-07-09 21:27:23 [main] INFO  org.apache.spark.SparkContext - Starting job: collectAsList at TransformationTest.java:72
2025-07-09 21:27:23 [dag-scheduler-event-loop] INFO  org.apache.spark.scheduler.DAGScheduler - Got job 1 (collectAsList at TransformationTest.java:72) with 1 output partitions
2025-07-09 21:27:23 [dag-scheduler-event-loop] INFO  org.apache.spark.scheduler.DAGScheduler - Final stage: ResultStage 2 (collectAsList at TransformationTest.java:72)
2025-07-09 21:27:23 [dag-scheduler-event-loop] INFO  org.apache.spark.scheduler.DAGScheduler - Parents of final stage: List(ShuffleMapStage 1)
2025-07-09 21:27:23 [dag-scheduler-event-loop] INFO  org.apache.spark.scheduler.DAGScheduler - Missing parents: List()
2025-07-09 21:27:23 [dag-scheduler-event-loop] INFO  org.apache.spark.scheduler.DAGScheduler - Submitting ResultStage 2 (MapPartitionsRDD[5] at collectAsList at TransformationTest.java:72), which has no missing parents
2025-07-09 21:27:23 [dag-scheduler-event-loop] INFO  org.apache.spark.storage.memory.MemoryStore - Block broadcast_1 stored as values in memory (estimated size 35.0 KiB, free 2.2 GiB)
2025-07-09 21:27:23 [dag-scheduler-event-loop] INFO  org.apache.spark.storage.memory.MemoryStore - Block broadcast_1_piece0 stored as bytes in memory (estimated size 15.7 KiB, free 2.2 GiB)
2025-07-09 21:27:23 [dispatcher-BlockManagerMaster] INFO  org.apache.spark.storage.BlockManagerInfo - Added broadcast_1_piece0 in memory on DESKTOP-1DMF534.bbrouter:55342 (size: 15.7 KiB, free: 2.2 GiB)
2025-07-09 21:27:23 [dag-scheduler-event-loop] INFO  org.apache.spark.SparkContext - Created broadcast 1 from broadcast at DAGScheduler.scala:1585
2025-07-09 21:27:23 [dag-scheduler-event-loop] INFO  org.apache.spark.scheduler.DAGScheduler - Submitting 1 missing tasks from ResultStage 2 (MapPartitionsRDD[5] at collectAsList at TransformationTest.java:72) (first 15 tasks are for partitions Vector(0))
2025-07-09 21:27:23 [dag-scheduler-event-loop] INFO  org.apache.spark.scheduler.TaskSchedulerImpl - Adding task set 2.0 with 1 tasks resource profile 0
2025-07-09 21:27:23 [dispatcher-event-loop-3] INFO  org.apache.spark.scheduler.TaskSetManager - Starting task 0.0 in stage 2.0 (TID 6) (DESKTOP-1DMF534.bbrouter, executor driver, partition 0, NODE_LOCAL, 8999 bytes) 
2025-07-09 21:27:23 [Executor task launch worker for task 0.0 in stage 2.0 (TID 6)] INFO  org.apache.spark.executor.Executor - Running task 0.0 in stage 2.0 (TID 6)
2025-07-09 21:27:23 [dispatcher-BlockManagerMaster] INFO  org.apache.spark.storage.BlockManagerInfo - Removed broadcast_0_piece0 on DESKTOP-1DMF534.bbrouter:55342 in memory (size: 9.9 KiB, free: 2.2 GiB)
2025-07-09 21:27:23 [Executor task launch worker for task 0.0 in stage 2.0 (TID 6)] INFO  org.apache.spark.storage.ShuffleBlockFetcherIterator - Getting 6 (448.0 B) non-empty blocks including 6 (448.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
2025-07-09 21:27:23 [Executor task launch worker for task 0.0 in stage 2.0 (TID 6)] INFO  org.apache.spark.storage.ShuffleBlockFetcherIterator - Started 0 remote fetches in 17 ms
2025-07-09 21:27:23 [Executor task launch worker for task 0.0 in stage 2.0 (TID 6)] INFO  org.apache.spark.sql.catalyst.expressions.codegen.CodeGenerator - Code generated in 24.662 ms
2025-07-09 21:27:23 [Executor task launch worker for task 0.0 in stage 2.0 (TID 6)] INFO  org.apache.spark.executor.Executor - Finished task 0.0 in stage 2.0 (TID 6). 5070 bytes result sent to driver
2025-07-09 21:27:23 [task-result-getter-2] INFO  org.apache.spark.scheduler.TaskSetManager - Finished task 0.0 in stage 2.0 (TID 6) in 204 ms on DESKTOP-1DMF534.bbrouter (executor driver) (1/1)
2025-07-09 21:27:23 [task-result-getter-2] INFO  org.apache.spark.scheduler.TaskSchedulerImpl - Removed TaskSet 2.0, whose tasks have all completed, from pool 
2025-07-09 21:27:23 [dag-scheduler-event-loop] INFO  org.apache.spark.scheduler.DAGScheduler - ResultStage 2 (collectAsList at TransformationTest.java:72) finished in 0.252 s
2025-07-09 21:27:23 [dag-scheduler-event-loop] INFO  org.apache.spark.scheduler.DAGScheduler - Job 1 is finished. Cancelling potential speculative or zombie tasks for this job
2025-07-09 21:27:23 [dag-scheduler-event-loop] INFO  org.apache.spark.scheduler.TaskSchedulerImpl - Killing all running tasks in stage 2: Stage finished
2025-07-09 21:27:23 [main] INFO  org.apache.spark.scheduler.DAGScheduler - Job 1 finished: collectAsList at TransformationTest.java:72, took 0.277205 s
2025-07-09 21:27:23 [main] INFO  org.apache.spark.sql.catalyst.expressions.codegen.CodeGenerator - Code generated in 6.9581 ms
2025-07-09 21:27:23 [main] INFO  org.apache.spark.SparkContext - SparkContext is stopping with exitCode 0.
2025-07-09 21:27:23 [main] INFO  org.sparkproject.jetty.server.AbstractConnector - Stopped Spark@4ac8768e{HTTP/1.1, (http/1.1)}{0.0.0.0:4040}
2025-07-09 21:27:23 [main] INFO  org.apache.spark.ui.SparkUI - Stopped Spark web UI at http://DESKTOP-1DMF534.bbrouter:4040
2025-07-09 21:27:23 [dispatcher-event-loop-7] INFO  org.apache.spark.MapOutputTrackerMasterEndpoint - MapOutputTrackerMasterEndpoint stopped!
2025-07-09 21:27:23 [main] INFO  org.apache.spark.storage.memory.MemoryStore - MemoryStore cleared
2025-07-09 21:27:23 [main] INFO  org.apache.spark.storage.BlockManager - BlockManager stopped
2025-07-09 21:27:23 [main] INFO  org.apache.spark.storage.BlockManagerMaster - BlockManagerMaster stopped
2025-07-09 21:27:23 [dispatcher-event-loop-3] INFO  org.apache.spark.scheduler.OutputCommitCoordinator$OutputCommitCoordinatorEndpoint - OutputCommitCoordinator stopped!
2025-07-09 21:27:23 [main] INFO  org.apache.spark.SparkContext - Successfully stopped SparkContext
2025-07-09 21:27:23 [shutdown-hook-0] INFO  org.apache.spark.util.ShutdownHookManager - Shutdown hook called
2025-07-09 21:27:23 [shutdown-hook-0] INFO  org.apache.spark.util.ShutdownHookManager - Deleting directory C:\Users\abuth\AppData\Local\Temp\spark-26a30460-c641-4a98-8049-5b7fda4e51ca
